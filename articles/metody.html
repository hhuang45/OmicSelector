<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="OmicSelector">
<title>OmicSelector: Available methods of feature selection and benchmarking. • OmicSelector</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><link href="../deps/_Roboto-0.4.1/font.css" rel="stylesheet">
<link href="../deps/_JetBrains%20Mono-0.4.1/font.css" rel="stylesheet">
<link href="../deps/_Roboto%20Slab-0.4.1/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="OmicSelector: Available methods of feature selection and benchmarking.">
<meta property="og:description" content="OmicSelector">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-53584749-8"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-53584749-8');
</script>
</head>
<body>
    <a href="#container" class="visually-hidden-focusable">Skip to content</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-none"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">OmicSelector</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"></ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="nav-link" href="../index.html">
    <span class="fa fa-home"></span>
     
    Introduction
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://www.youtube.com/watch?v=dKUdINEcOjk">
    <span class="fa fa-video"></span>
     
    Tutorial (GUI)
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://biostat.umed.pl/OmicSelector/demo/">
    <span class="fa fa-cubes"></span>
     
    Demo
  </a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">
    <span class="fa fa-file-code"></span>
     
    Functions
  </a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../articles/metody.html">
    <span class="fa fa-tools"></span>
     
    Methods
  </a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown--tutorials-code-">
    <span class="fas fa fas fa-book"></span>
     
    Tutorials (Code)
  </a>
  <div class="dropdown-menu" aria-labelledby="dropdown--tutorials-code-">
    <a class="dropdown-item" href="../articles/Tutorial.html">
      <span class="fa fa-user-graduate"></span>
       
      Basic analysis tutorial
    </a>
    <a class="dropdown-item" href="../articles/DeepLearningTutorial.html">
      <span class="fa fa-code-branch"></span>
       
      Deep learning tutorial
    </a>
  </div>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/kstawiski/OmicSelector/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="http://twitter.com/KonradStawiski" aria-label="Twitter">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article" id="container">

<div class="row">
  <main id="main"><div class="page-header">
      <img src="" class="logo" alt=""><h1>OmicSelector: Available methods of feature selection and benchmarking.</h1>
                        <h4 data-toc-skip class="author">Konrad Stawiski</h4>
            <address class="author_afil">
      Department of Biostatistics and Translational Research, Medical University of Lodz, Lodz, Poland (<a href="https://biostat.umed.pl" class="external-link uri">https://biostat.umed.pl</a>)<br><a class="author_email" href="mailto:#"></a><a href="mailto:konrad.stawiski@umed.lodz.pl" class="email">konrad.stawiski@umed.lodz.pl</a>
      </address>
                              <h4 data-toc-skip class="author">Marcin Kaszkowiak</h4>
            <address class="author_afil">
      Department of Biostatistics and Translational Research, Medical University of Lodz, Lodz, Poland (<a href="https://biostat.umed.pl" class="external-link uri">https://biostat.umed.pl</a>)<br><small class="dont-index">Source: <a href="https://github.com/kstawiski/OmicSelector/blob/HEAD/vignettes/metody.Rmd" class="external-link"><code>vignettes/metody.Rmd</code></a></small>
      <div class="d-none name"><code>metody.Rmd</code></div>
    </address>
</div>

    
    
<p>The main purpose of OmicSelector is to give you the set of candidate features for further validation of biomarker study. The package performs feature selection first. In the next step the sets of features are tested in the process called “benchmarking”. In benchmarking we test all of those sets of features (biomarkers) using various data-mining (machine learning) methods. Based on the avarage performance of sets in cross-validation or holdout-validation (testing on test set and/or validation set) we can sugesst which of the signatures (set of features) is have the greatest potential in further validation.</p>
<p>Please note that presented methods below are those avaiable in GUI (via web browser). Those can be further extended with ease by users with intermediate R knowledge. Please refer to our extension manuals (comming soon).</p>
<div class="section level2">
<h2 id="feature-selection-methods">Feature selection methods<a class="anchor" aria-label="anchor" href="#feature-selection-methods"></a>
</h2>
<table class="table table">
<thead>
<th>ID</th>
<th>Description</th>
</thead>
<tbody>
<tr>
<td>No: 1<br><code>all<code></code></code>
</td>
        <td>Get all features (all features staring with 'hsa').</td>
    </tr>
<tr>
<td>No: 2<br><code>sig, sigtop, sigtopBonf, sigtopHolm, topFC, sigSMOTE, sigtopSMOTE, sigtopBonfSMOTE, sigtopHolmSMOTE, topFCSMOTE</code>
</td>
        <td>Selects features significantly differently expressed between classes by performing unpaired t-test with and without correction for multiple testing. We get: <code>sig</code> - all significant (adjusted p-value less or equal to 0.05) miRNAs with comparison using unpaired t-test and after the Benjamini-Hochberg procedure (BH, false discovery rate); <code>sigtop</code> - <code>sig</code> but limited only to the your prefered number of features (most significant features sorted by p-value), <code>sigtopBonf</code> - uses Bonferroni instead of BH correction, <code>sigtopHolm</code> - uses Holm–Bonferroni instead of BH correction, <code>topFC</code> - selects prefered number of features based on decreasing absolute value of fold change in differential analysis.
        <br>All the methods are also checked on dataset balanced with SMOTE (<a href="https://arxiv.org/pdf/1106.1813.pdf" target="_blank" class="external-link">Synthetic Minority Oversampling TEchnique</a>) - those formulas which names are appended with <code>SMOTE</code>.</td>
    </tr>
<tr>
<td>No: 3<br><code>fcsig, fcsigSMOTE</code>
</td>
        <td>Features significant in DE analysis using unpaired t-test and which absolute log2FC is greater than 1. Thus, features significant and up- or down-regulated in the higher magnitudes. FC - fold-change, DE - differential analysis.</td>
    </tr>
<tr>
<td>No: 4<br><code>cfs, cfsSMOTE, cfs_sig, cfsSMOTE_sig</code>
</td>
        <td>
<a href="https://www.cs.waikato.ac.nz/~mhall/thesis.pdf" target="_blank" class="external-link">Correlation-based feature selection</a> (CFS) - a heuristic algorithm selecting features that are highly correlated with class (binary) and lowly correlated with one another. It explores a search space in best-first manner, until stopping criteria are met.</td>
    </tr>
<tr>
<td>No: 5<br><code>classloop</code>
</td>
        <td>Classifier loop - performs multiple classification procedures using various algorithms (with embedded feature ranking) and various performance metrices. Final feature selection is done by combining the results. Modeling methods used: support vector machines, linear discriminant a nalysis, random forest and nearest shrunken centroid. Features are selected based on the AUC ROC and assessed in k-fold cross-validation according to the <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/classifier.loop" target="_blank" class="external-link">documentation</a>. As this requires time, we do not perform it on SMOTEd dataset.</td>
    </tr>
<tr>
<td>No: 6<br><code>classloopSMOTE</code>
</td>
        <td>Application of <code>classloop</code> on balanced dataset (with SMOTE).</td>
    </tr>
<tr>
<td>No: 7<br><code>classloop_sig</code>
</td>
        <td>Application of <code>classloop</code> but only on the features which are significant in DE.</td>
    </tr>
<tr>
<td>No: 8<br><code>classloopSMOTE_sig</code>
</td>
        <td>Application of <code>classloop</code> on balanced training set and only on the features which are significant in DE (after balancing).</td>
    </tr>
<tr>
<td>No: 9<br><code>fcfs</code>
</td>
        <td>An algorithm similar to CFS, though exploring search space in greedy forward search manner (adding one, most attractive, feature at the time, until such addition does not improve set’s overall quality). Based on <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.411.9868&amp;rep=rep1&amp;type=pdf" target="_blank" class="external-link">Wang et al. 2005</a> and documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.forward.Corr" target="_blank" class="external-link">here</a>.</td>
    </tr>
<tr>
<td>No: 10<br><code>fcfsSMOTE</code>
</td>
        <td>Application of <code>fcfs</code> on balanced training set.</td>
    </tr>
<tr>
<td>No: 11<br><code>fcfs_sig</code>
</td>
        <td>Application of <code>fcfs</code> on features significant in DE.</td>
    </tr>
<tr>
<td>No: 12<br><code>fcfsSMOTE_sig</code>
</td>
        <td>Application of <code>fcfs</code> on balanced dataset and on features significant in DE (after balancing).</td>
    </tr>
<tr>
<td>No: 13<br><code>fwrap</code>
</td>
        <td>A decision tree algorithm and forward search strategy documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.forward.wrapper" target="_blank" class="external-link">here</a>.</td>
    </tr>
<tr>
<td>No: 14<br><code>fwrapSMOTE</code>
</td>
        <td>Application of <code>fwrap</code> on balanced training set.</td>
    </tr>
<tr>
<td>No: 15<br><code>fwrap_sig</code>
</td>
        <td>Application of <code>fwrap</code> on features significant in DE.</td>
    </tr>
<tr>
<td>No: 16<br><code>fwrapSMOTE_sig</code>
</td>
        <td>Application of <code>fwrap</code> on balanced dataset and on features significant in DE (after balancing).</td>
    </tr>
<tr>
<td>No: 17<br><code>AUC_MDL</code>
</td>
        <td>Feature ranking based on ROC AUC and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below.</td>
    </tr>
<tr>
<td>No: 18<br><code>SU_MDL</code>
</td>
        <td>Feature ranking based on symmetrical uncertainty and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below.</td>
    </tr>
<tr>
<td>No: 19<br><code>CorrSF_MDL</code>
</td>
        <td>Feature ranking based on CFS algorithm with forward search and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below.</td>
    </tr>
<tr>
<td>No: 20<br><code>AUC_MDLSMOTE</code>
</td>
        <td>Feature ranking based on ROC AUC and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below. Performed on the training set balanced with SMOTE.</td>
    </tr>
<tr>
<td>No: 21<br><code>SU_MDLSMOTE</code>
</td>
        <td>Feature ranking based on symmetrical uncertainty and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below. Performed on the training set balanced with SMOTE.</td>
    </tr>
<tr>
<td>No: 22<br><code>CorrSF_MDLSMOTE</code>
</td>
        <td>Feature ranking based on CFS algorithm with forward search and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below. Performed on the training set balanced with SMOTE.</td>
    </tr>
<tr>
<td>No: 23<br><code>AUC_MDL_sig</code>
</td>
        <td>Feature ranking based on ROC AUC and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below. Only features significant in DE are allowed.</td>
    </tr>
<tr>
<td>No: 24<br><code>SU_MDL_sig</code>
</td>
        <td>Feature ranking based on symmetrical uncertainty and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below. Only features significant in DE are allowed.</td>
    </tr>
<tr>
<td>No: 25<br><code>CorrSF_MDL_sig</code>
</td>
        <td>Feature ranking based on CFS algorithm with forward search and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below. Only features significant in DE are allowed.</td>
    </tr>
<tr>
<td>No: 26<br><code>AUC_MDLSMOTE_sig</code>
</td>
        <td>Feature ranking based on ROC AUC and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below. Performed on the training set balanced with SMOTE. Only features significant in DE are allowed.</td>
    </tr>
<tr>
<td>No: 27<br><code>SU_MDLSMOTE_sig</code>
</td>
        <td>Feature ranking based on symmetrical uncertainty and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below. Performed on the training set balanced with SMOTE. Only features significant in DE are allowed.</td>
    </tr>
<tr>
<td>No: 28<br><code>CorrSF_MDLSMOTE_sig</code>
</td>
        <td>Feature ranking based on CFS algorithm with forward search and minimal description length (MDL) discretization algorithm documented <a href="https://www.rdocumentation.org/packages/Biocomb/versions/0.4/topics/select.process" target="_blank" class="external-link">here</a>. After the ranking, the number of features are limited as set in options below. Performed on the training set balanced with SMOTE. Only features significant in DE are allowed.</td>
    </tr>
<tr>
<td>No: 29<br><code>bounceR-full, bounceR-stability</code>
</td>
        <td>A component-wise-boosting-based algorithm selecting optimal features in multiple iterations of single feature-models construction. See the source <a href="https://github.com/STATWORX/bounceR" target="_blank" class="external-link">here</a>. <code>bounceR-stability</code> gets the most stable features. Wrapper methods implemented here leverage componentwise boosting as a weak learners.</td>
    </tr>
<tr>
<td>No: 30<br><code>bounceR-full_SMOTE, bounceR-stability_SMOTE</code>
</td>
        <td>A component-wise-boosting-based algorithm selecting optimal features in multiple iterations of single feature-models construction. See the source <a href="https://github.com/STATWORX/bounceR" target="_blank" class="external-link">here</a>. <code>bounceR-stability</code> gets the most stable features. Wrapper methods implemented here leverage componentwise boosting as a weak learners. Performed on the training set balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 31<br><code>bounceR-full_SIG, bounceR-stability_SIG</code>
</td>
        <td>A component-wise-boosting-based algorithm selecting optimal features in multiple iterations of single feature-models construction. See the source <a href="https://github.com/STATWORX/bounceR" target="_blank" class="external-link">here</a>. <code>bounceR-stability</code> gets the most stable features. Wrapper methods implemented here leverage componentwise boosting as a weak learners. Only features significant in DE are allowed. </td>
    </tr>
<tr>
<td>No: 32<br><code>bounceR-full_SIGSMOTE, bounceR-stability_SIGSMOTE</code>
</td>
        <td>A component-wise-boosting-based algorithm selecting optimal features in multiple iterations of single feature-models construction. See the source <a href="https://github.com/STATWORX/bounceR" target="_blank" class="external-link">here</a>. <code>bounceR-stability</code> gets the most stable features. Wrapper methods implemented here leverage componentwise boosting as a weak learners. Only features significant in DE are allowed. Performed on the training set balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 33<br><code>RandomForestRFE</code>
</td>
        <td>Recursively eliminates features from the feature space based on ranking from Random Forrest classifier (retrained woth resampling after each elimination). Details are available <a href="https://topepo.github.io/caret/recursive-feature-elimination.html#search" target="_blank" class="external-link">here</a>. </td>
    </tr>
<tr>
<td>No: 34<br><code>RandomForestRFESMOTE</code>
</td>
        <td>Recursively eliminates features from the feature space based on ranking from Random Forrest classifier (retrained woth resampling after each elimination). Details are available <a href="https://topepo.github.io/caret/recursive-feature-elimination.html#search" target="_blank" class="external-link">here</a>. Performed on the training set balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 35<br><code>RandomForestRFE_sig</code>
</td>
        <td>Recursively eliminates features from the feature space based on ranking from Random Forrest classifier (retrained woth resampling after each elimination). Details are available <a href="https://topepo.github.io/caret/recursive-feature-elimination.html#search" target="_blank" class="external-link">here</a>. Only features significant in DE are allowed.  </td>
    </tr>
<tr>
<td>No: 36<br><code>RandomForestRFESMOTE_sig</code>
</td>
        <td>Recursively eliminates features from the feature space based on ranking from Random Forrest classifier (retrained woth resampling after each elimination). Details are available <a href="https://topepo.github.io/caret/recursive-feature-elimination.html#search" target="_blank" class="external-link">here</a>. Only features significant in DE are allowed. Performed on the training set balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 37<br><code>GeneticAlgorithmRF</code>
</td>
        <td>Uses genetic algorithm principle to search for optimal subset of the feature space. This uses internally implemented random forest model and 10-fold cross validation to assess performance of the "chromosomes" in each generation. Details are available <a href="https://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html" target="_blank" class="external-link">here</a>. </td>
    </tr>
<tr>
<td>No: 38<br><code>GeneticAlgorithmRFSMOTE</code>
</td>
        <td>Uses genetic algorithm principle to search for optimal subset of the feature space. This uses internally implemented random forest model and 10-fold cross validation to assess performance of the "chromosomes" in each generation. Details are available <a href="https://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html" target="_blank" class="external-link">here</a>. Performed on the training set balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 39<br><code>GeneticAlgorithmRF_sig</code>
</td>
        <td>Uses genetic algorithm principle to search for optimal subset of the feature space. This uses internally implemented random forest model and 10-fold cross validation to assess performance of the "chromosomes" in each generation. Details are available <a href="https://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html" target="_blank" class="external-link">here</a>. Only features significant in DE are allowed.  </td>
    </tr>
<tr>
<td>No: 40<br><code>GeneticAlgorithmRFSMOTE_sig</code>
</td>
        <td>Uses genetic algorithm principle to search for optimal subset of the feature space. This uses internally implemented random forest model and 10-fold cross validation to assess performance of the "chromosomes" in each generation. Details are available <a href="https://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html" target="_blank" class="external-link">here</a>. Only features significant in DE are allowed. Performed on the training set balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 41<br><code>SimulatedAnnealingRF</code>
</td>
        <td>Simulated Annealing - explores a feature space by randomly modifying a given feature subset and evaluating classification performance using new attributes to check whether changes were beneficial. It is is a global search method that makes small random changes (i.e. perturbations) to an initial candidate solution. In this method also random forest is used as a model for evaluation. Details are available <a href="https://topepo.github.io/caret/feature-selection-using-simulated-annealing.html" target="_blank" class="external-link">here</a>. </td>
    </tr>
<tr>
<td>No: 42<br><code>SimulatedAnnealingRFSMOTE</code>
</td>
        <td>Simulated Annealing - explores a feature space by randomly modifying a given feature subset and evaluating classification performance using new attributes to check whether changes were beneficial. It is is a global search method that makes small random changes (i.e. perturbations) to an initial candidate solution. In this method also random forest is used as a model for evaluation. Details are available <a href="https://topepo.github.io/caret/feature-selection-using-simulated-annealing.html" target="_blank" class="external-link">here</a>. Performed on the training set balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 43<br><code>SimulatedAnnealingRF_sig</code>
</td>
        <td>Simulated Annealing - explores a feature space by randomly modifying a given feature subset and evaluating classification performance using new attributes to check whether changes were beneficial. It is is a global search method that makes small random changes (i.e. perturbations) to an initial candidate solution. In this method also random forest is used as a model for evaluation. Details are available <a href="https://topepo.github.io/caret/feature-selection-using-simulated-annealing.html" target="_blank" class="external-link">here</a>. Only features significant in DE are allowed.  </td>
    </tr>
<tr>
<td>No: 44<br><code>SimulatedAnnealingRFSMOTE_sig</code>
</td>
        <td>Simulated Annealing - explores a feature space by randomly modifying a given feature subset and evaluating classification performance using new attributes to check whether changes were beneficial. It is is a global search method that makes small random changes (i.e. perturbations) to an initial candidate solution. In this method also random forest is used as a model for evaluation. Details are available <a href="https://topepo.github.io/caret/feature-selection-using-simulated-annealing.html" target="_blank" class="external-link">here</a>. Only features significant in DE are allowed. Performed on the training set balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 45<br><code>Boruta</code>
</td>
        <td>Boruta - utilizes random forrest algorithm to iteratively remove features proved to be less relevant than random variables. Details are available in paper by <a href="https://www.jstatsoft.org/v36/i11/paper/" target="_blank" class="external-link">Kursa et al. 2010</a> or <a href="https://www.datacamp.com/community/tutorials/feature-selection-R-boruta" target="_blank" class="external-link">this blog post</a>. Only features significant in DE are allowed. Performed on the training set balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 46<br><code>BorutaSMOTE</code>
</td>
        <td>Boruta - utilizes random forrest algorithm to iteratively remove features proved to be less relevant than random variables. Details are available in paper by <a href="https://www.jstatsoft.org/v36/i11/paper/" target="_blank" class="external-link">Kursa et al. 2010</a> or <a href="https://www.datacamp.com/community/tutorials/feature-selection-R-boruta" target="_blank" class="external-link">this blog post</a>. Performed on the training set balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 47<br><code>spFSR</code>
</td>
        <td>spFSR - feature selection and ranking by simultaneous perturbation stochastic approximation. This is an algorithm based on pseudo-gradient descent stochastic optimisation with Barzilai-Borwein method for step size and gradient estimation optimization.  Details are available in paper by <a href="https://arxiv.org/abs/1804.05589" target="_blank" class="external-link">Zeren et al. 2018</a>. </td>
    </tr>
<tr>
<td>No: 48<br><code>spFSRSMOTE</code>
</td>
        <td>spFSR - feature selection and ranking by simultaneous perturbation stochastic approximation. This is an algorithm based on pseudo-gradient descent stochastic optimisation with Barzilai-Borwein method for step size and gradient estimation optimization. Details are available in paper by <a href="https://arxiv.org/abs/1804.05589" target="_blank" class="external-link">Zeren et al. 2018</a>. Performed on the training set balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 49<br><code>varSelRF, varSelRFSMOTE</code>
</td>
        <td>varSelRF - recursively eliminates features using random forrest feature scores, seeking to minimize out-of-bag classification error.  Details are available in paper by <a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-3" target="_blank" class="external-link">Díaz-Uriarte et al. 2006</a>. Performed on the unbalanced training set as well as on balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 50<br><code>Wx, WxSMOTE</code>
</td>
        <td>Wx - deep neural network-based (deep learning) feature (gene) selection algorithm. <a href="https://github.com/kstawiski/OmicSelector/blob/master/inst/extdata/wx/DearWXpub/src/wx_konsta.py" target="_blank" class="external-link">We use 2 hidden layers with 16 hidden neurons.</a> Details are available in paper by <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6642261/" target="_blank" class="external-link">Park et al. 2019</a>. Performed on the unbalanced training set as well as on balanced with SMOTE. </td>
    </tr>
<tr>
<td>No: 51<br><code>Mystepwise_glm_binomial, Mystepwise_sig_glm_binomial</code>
</td>
        <td>Stepwise variable selection procedure (with iterations between the 'forward' and 'backward' steps) for generalized linear models with logit link function (i.e. logistic regression). We use p=0.05 as a threshold for both entry (SLE) and stay (SLS). Details are available <a href="https://www.rdocumentation.org/packages/My.stepwise" target="_blank" class="external-link">here</a>. Performed on all features of training set as well as features initially selected in DE (significant in DE). </td>
    </tr>
<tr>
<td>No: 52<br><code>Mystepwise_glm_binomialSMOTE, Mystepwise_sig_glm_binomialSMOTE</code>
</td>
        <td>Stepwise variable selection procedure (with iterations between the 'forward' and 'backward' steps) for generalized linear models with logit link function (i.e. logistic regression). We use p=0.05 as a threshold for both entry (SLE) and stay (SLS). Details are available <a href="https://www.rdocumentation.org/packages/My.stepwise" target="_blank" class="external-link">here</a>. Performed on all features of training set as well as features initially selected in DE (significant in DE) after balancing the training set with SMOTE. </td>
    </tr>
<tr>
<td>No: 53<br><code>stepAIC, stepAICsig</code>
</td>
        <td>Here we perform a stepwise model selection by AIC (Akaike Information Criterion) based on logistic regression. Details are available <a href="https://www.rdocumentation.org/packages/MASS/versions/7.3-53/topics/stepAIC" target="_blank" class="external-link">here</a>. Performed on all features of training set as well as features initially selected in DE (significant in DE). </td>
    </tr>
<tr>
<td>No: 54<br><code>stepAIC_SMOTE, stepAICsig_SMOTE</code>
</td>
        <td>Here we perform a stepwise model selection by AIC (Akaike Information Criterion) based on logistic regression. Details are available <a href="https://www.rdocumentation.org/packages/MASS/versions/7.3-53/topics/stepAIC" target="_blank" class="external-link">here</a>. Performed on all features of training set as well as features initially selected in DE (significant in DE) after balancing the training set with SMOTE. </td>
    </tr>
<tr>
<td>No: 55<br><code>iteratedRFECV, iteratedRFETest</code>
</td>
        <td>Iterated RFE tested in cross-validation and on test set (watch out for bias!). See the source <a href="https://github.com/kstawiski/OmicSelector/blob/master/R/OmicSelector_iteratedRFE.R" target="_blank" class="external-link">here</a>.</td>
    </tr>
<tr>
<td>No: 56<br><code>iteratedRFECV_SMOTE, iteratedRFETest_SMOTE</code>
</td>
        <td>Iterated RFE tested in cross-validation and on test set (watch out for bias!). See the source <a href="https://github.com/kstawiski/OmicSelector/blob/master/R/OmicSelector_iteratedRFE.R" target="_blank" class="external-link">here</a>. Performed after balancing the training set with SMOTE. </td>
    </tr>
<tr>
<td>No: 57<br><code>LASSO, LASSO_SMOTE</code>
</td>
        <td>Feature selection based on LASSO (Least Absolute Shrinkage and Selection Operator) model with alpha = 1  - penalizes with L1-norm; with 10-fold cross-validation. See the source <a href="https://www.rdocumentation.org/packages/glmnet/versions/4.0-2/topics/glmnet" target="_blank" class="external-link">here</a>. Performed on originial training set and after balancing the training set with SMOTE. </td>
    </tr>
<tr>
<td>No: 58<br><code>ElasticNet, ElasticNet_SMOTE</code>
</td>
        <td>Feature selection based on elastic net with tuning the value of alpha through a line search. See the source <a href="https://www.rdocumentation.org/packages/glmnet/versions/4.0-2/topics/glmnet" target="_blank" class="external-link">here</a>. Performed on originial training set and after balancing the training set with SMOTE. </td>
    </tr>
<tr>
<td>No: 59<br><code>stepLDA, stepLDA_SMOTE</code>
</td>
        <td>Forward/backward variable selection (both directions) for linear discriminant analysis. See the source <a href="https://www.rdocumentation.org/packages/klaR" target="_blank" class="external-link">here</a>. Performed on originial training set and after balancing the training set with SMOTE. </td>
    </tr>
<tr>
<td>No: 60<br><code>feseR_filter.corr, feseR_gain.inf, feseR_matrix.corr, feseR_combineFS_RF, feseR_filter.corr_SMOTE, feseR_gain.inf_SMOTE, feseR_matrix.corr_SMOTE, feseR_combineFS_RF_SMOTE</code>
</td>
        <td>Set of feature selection methods embeded in feseR package published by Perez-Rivelor et al. All default parameters are used, but mincorr is set to 0.2. See the paper <a href="https://doi.org/10.1371/journal.pone.0189875" target="_blank" class="external-link">here</a>. Performed on originial training set and after balancing the training set with SMOTE. </td>
    </tr>
</tbody>
</table>
<p>Those methods can be applied via GUI or via <code><a href="../reference/OmicSelector_OmicSelector.html">OmicSelector_OmicSelector()</a></code> function in the R package.</p>
</div>
<div class="section level2">
<h2 id="benchmarking-data-minig-modelling-methods">Benchmarking (data-minig modelling methods)<a class="anchor" aria-label="anchor" href="#benchmarking-data-minig-modelling-methods"></a>
</h2>
<p>The GUI offers server data-mining algorithms which can be used in benchmarking:</p>
<table class="table table">
<thead><tr>
<th>ID</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr>
<td><code>glm<code></code></code></td>
        <td>Logistic regression (generalized linear model with binomial link function).</td>
        </tr>
<tr>
<td><code>mlp<code></code></code></td>
          <td>Multilayer perceptron (MLP) -  fully connected feedforward neural network with 1 hidden layer and logistic activiation function. Details: <a href="https://github.com/topepo/caret/blob/master/models/files/mlp.R" target="_blank" class="external-link">code</a>, <a href="https://www.rdocumentation.org/packages/RSNNS" target="_blank" class="external-link">package</a>.</td>
            </tr>
<tr>
<td><code>mlpML<code></code></code></td>
              <td>Multilayer perceptron (MLP) -  fully connected feedforward neural network with up to 3 hidden layers and logistic activiation function. Details: <a href="https://github.com/topepo/caret/blob/master/models/files/mlpML.R" target="_blank" class="external-link">code</a>, <a href="https://www.rdocumentation.org/packages/RSNNS" target="_blank" class="external-link">package</a>.</td>
                </tr>
<tr>
<td><code>svmRadial<code></code></code></td>
                  <td>Support vector machines with radial basis function kernel. Details: <a href="https://github.com/topepo/caret/blob/master/models/files/svmRadial.R" target="_blank" class="external-link">code</a>, <a href="https://www.rdocumentation.org/packages/kernlab" target="_blank" class="external-link">package</a>.</td>
                    </tr>
<tr>
<td><code>svmLinear<code></code></code></td>
                      <td>Support vector machines with linear kernel. Details: <a href="https://github.com/topepo/caret/blob/master/models/files/svmLinear.R" target="_blank" class="external-link">code</a>, <a href="https://www.rdocumentation.org/packages/kernlab" target="_blank" class="external-link">package</a>.</td>
                        </tr>
<tr>
<td><code>rf<code></code></code></td>
                          <td>Random forest. Details: <a href="https://github.com/topepo/caret/blob/master/models/files/rf.R" target="_blank" class="external-link">code</a>, <a href="https://www.rdocumentation.org/packages/randomForest" target="_blank" class="external-link">package</a>.</td>
                            </tr>
<tr>
<td><code>C5.0<code></code></code></td>
                              <td>C5.0 decision trees and rule-based models. Details: <a href="https://github.com/topepo/caret/blob/master/models/files/C5.0.R" target="_blank" class="external-link">code</a>, <a href="https://www.rdocumentation.org/packages/C50" target="_blank" class="external-link">package</a>.</td>
                                </tr>
<tr>
<td><code>rpart<code></code></code></td>
                                  <td>CART decision trees with modulation of complexity parameter. Details: <a href="https://github.com/topepo/caret/blob/master/models/files/rpart.R" target="_blank" class="external-link">code</a>, <a href="https://www.rdocumentation.org/packages/rpart" target="_blank" class="external-link">package</a>.</td>
                                    </tr>
<tr>
<td><code>rpart2<code></code></code></td>
                                      <td>CART decision trees with modulation of max tree depth. Details: <a href="https://github.com/topepo/caret/blob/master/models/files/rpart2.R" target="_blank" class="external-link">code</a>, <a href="https://www.rdocumentation.org/packages/rpart" target="_blank" class="external-link">package</a>.</td>
                                        </tr>
<tr>
<td><code>ctree<code></code></code></td>
                                          <td>Conditional inference trees. Details: <a href="https://github.com/topepo/caret/blob/master/models/files/ctree.R" target="_blank" class="external-link">code</a>, <a href="https://www.rdocumentation.org/packages/party" target="_blank" class="external-link">package</a>.</td>
                                            </tr>
<!-- <tr>

                                              <td><code>mxnet<code></td>
                                              <td>MXNET-based deep neural networks up to 2 hidden layers, with multiple activation functions tested. Note that predefined grid search is used in hyperparameter optimization for this method (not random search). Details: <a href="https://github.com/kstawiski/OmicSelector/blob/master/R/OmicSelector_benchmark.R#L173" target="_blank">code</a>, <a href="https://mxnet.apache.org/" target="_blank">package</a>.
                                              <br>
                                                It uses early stopping with set by user maximum number of epochs.
                                                  </td>
                                                  </tr> --><tr>
<td><code>xgbTree<code></code></code></td>
                                                    <td>eXtreme gradient boosting. (note: this is a time-consuming method). Details: <a href="https://github.com/topepo/caret/blob/master/models/files/xgbTree.R" target="_blank" class="external-link">code</a>, <a href="https://www.rdocumentation.org/packages/xgboost" target="_blank" class="external-link">package</a>.</td>
                                                      </tr>
</tbody>
</table>
<p>However, the <code><a href="../reference/OmicSelector_benchmark.html">OmicSelector_benchmark()</a></code> function works using <a href="https://topepo.github.io/caret/" class="external-link">caret</a>, meaning that every model from the (caret list of methods)[<a href="https://topepo.github.io/caret/available-models.html" class="external-link uri">https://topepo.github.io/caret/available-models.html</a>] can be applied (assuming that the depending packages are installed; see the reference of <code><a href="../reference/OmicSelector_benchmark.html">OmicSelector_benchmark()</a></code> for more details).</p>
<p>Note that the package performs the random search of hyperparameters. The best set of hyperparameters is chosen based on the performance on testing set (holdout validation) or strictly on training set (using cross-validation).</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



   </div>
  <footer><div class="container">
  <div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Konrad Stawiski, Marcin Kaszkowiak.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.3.</p>
</div>

  </div></footer>
</body>
</html>
